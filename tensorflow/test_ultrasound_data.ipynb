{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from data import read_data\n",
    "from utils import add_noise_est, normalize, add_noise, read_div2k_data\n",
    "\n",
    "from model_mwcnn import MWCNN\n",
    "from model_baseline import Unet\n",
    "from model_kpn import KPN, LossFunc, LossBasic\n",
    "\n",
    "gpu_ok = tf.test.is_gpu_available()\n",
    "print(\"tf version:\", tf.__version__)\n",
    "print(\"use GPU:\", gpu_ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "#model = Unet(color = False, filter_size=(5,5), channel_att=False, spatial_att=True, if_wavelet=False)\n",
    "#model = MWCNN(color = False, filter_size=(5,5), channel_att=False, spatial_att=False)\n",
    "model = KPN(color=False, burst_length=1, blind_est=True, sep_conv=False, kernel_size=[3],\n",
    "            channel_att=False, spatial_att=True, core_bias=True, use_bias=True)\n",
    "\n",
    "filename = 'kpn_ks3_satt_bias_combinedloss'\n",
    "\n",
    "load_model = True\n",
    "if load_model:\n",
    "    model.load_weights(filepath = \"model_weights/transfer_to_div2k/\" + filename + \".ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X_p, train_Y_p), (test_X_p, test_Y_p) = read_data('div2k')\n",
    "N_ims= len(train_X_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test data\n",
    "num = 5\n",
    "fname = \"./DIV2K_database/DIV2K_valid_HR\"\n",
    "test_X, test_Y = read_div2k_data(fname, num, if_normalized=True)\n",
    "\n",
    "labels = [test_X[i][0] for i in range(num)]\n",
    "test_X = [tf.expand_dims(tf.expand_dims(test_X[i][1], axis=-1), axis=0) for i in range(num) if test_X[i][1].shape[0]%8==0 and test_X[i][1].shape[1]%8==0]\n",
    "test_Y = [tf.expand_dims(tf.expand_dims(test_Y[i][1], axis=-1), axis=0) for i in range(num) if test_Y[i][1].shape[0]%8==0 and test_Y[i][1].shape[1]%8==0]\n",
    "\n",
    "num_tested = len(test_X)\n",
    "print('Totally', num_tested, 'images to be tested')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use generator to handle inputs of different sizes\n",
    "def generator():\n",
    "    for (test_x, test_y) in zip(test_X, test_Y):\n",
    "        yield (test_x, test_y)\n",
    "\n",
    "#test_dataset = tf.data.Dataset.from_tensor_slices((test_X,test_Y))\n",
    "test_dataset = tf.data.Dataset.from_generator(generator = generator, output_types = (tf.float32, tf.float32))\n",
    "test_dataset = test_dataset.batch(1).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on the full images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_Y = []\n",
    "for step, (test_x, test_y) in enumerate(test_dataset.take(num_tested)):\n",
    "    print(test_x.shape)\n",
    "    pred_y, _, _ = model(test_x, tf.expand_dims(test_x[...,0], axis=-1))\n",
    "    pred_Y.append(pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (50,10*num_tested))\n",
    "i = 1\n",
    "    \n",
    "for n in range(num_tested):\n",
    "    plt.subplot(num_tested,3,i)\n",
    "    plt.imshow(test_X[n].numpy().squeeze(), cmap='gray')\n",
    "    #plt.title('noise var {:.3f}'.format(test_x[n][...,1].mean()))\n",
    "    plt.axis('off')\n",
    "    i += 1\n",
    "\n",
    "    plt.subplot(num_tested,3,i)\n",
    "    plt.imshow(test_Y[n].numpy().squeeze(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    i += 1\n",
    "    \n",
    "    plt.subplot(num_tested,3,i)\n",
    "    plt.imshow(pred_Y[n].numpy().squeeze(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    i += 1\n",
    "\n",
    "plt.savefig('./results/images/transfer_to_div2k/full_images/outputs_ks3.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "def error(x1, x2, mode='mse'):\n",
    "    if mode == 'mse':\n",
    "        return np.mean(np.square(x1-x2))\n",
    "    elif mode == 'mae':\n",
    "        return np.mean(np.abs(x1-x2))\n",
    "    return\n",
    "\n",
    "psnr_gt_n = ssim_gt_n = error_gt_n = 0\n",
    "psnr_r_n = ssim_r_n = error_r_n = 0\n",
    "for i in range(num_tested):\n",
    "    psnr_gt_n += psnr(test_X[i].numpy().squeeze(), test_Y[i].numpy().squeeze(), data_range=1)\n",
    "    ssim_gt_n += ssim(test_X[i].numpy().squeeze(), test_Y[i].numpy().squeeze(), data_range=1)\n",
    "    error_gt_n += error(test_X[i].numpy().squeeze(), test_Y[i].numpy().squeeze())\n",
    "    \n",
    "    psnr_r_n += psnr(pred_Y[i].numpy().squeeze(), test_Y[i].numpy().squeeze(), data_range=1)\n",
    "    ssim_r_n += ssim(pred_Y[i].numpy().squeeze(), test_Y[i].numpy().squeeze(), data_range=1)\n",
    "    error_r_n += error(pred_Y[i].numpy().squeeze(), test_Y[i].numpy().squeeze())\n",
    "\n",
    "print('Evaluation of ground truth and noised images:')\n",
    "print('psnr:{:.3f}\\tssmi:{:.3f}\\tmse:{:.3f}'.format(psnr_gt_n/num_tested, ssim_gt_n/num_tested, error_gt_n/num_tested))\n",
    "\n",
    "print('\\nEvaluation of recovered images and noised images:')\n",
    "print('psnr:{:.3f}\\tssmi:{:.3f}\\tmse:{:.3f}'.format(psnr_r_n/num_tested, ssim_r_n/num_tested, error_r_n/num_tested))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the clusters to simulate the kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kernel_size = [3,5,7]\n",
    "\n",
    "def apply_filtering(frames, core, bias, kernel_size):\n",
    "    img_stack = []\n",
    "    pred_img = []\n",
    "    kernel = kernel_size[::-1]\n",
    "    for index, K in enumerate(kernel):\n",
    "        if not len(img_stack):\n",
    "            frame_pad = tf.pad(frames, paddings=[[0,0], [0,0], [K//2,K//2], [K//2,K//2], [0,0]], mode='constant')\n",
    "            for i in range(K):\n",
    "                for j in range(K):\n",
    "                    img_stack.append(frame_pad[:, :, i:i+height, j:j+width,:])\n",
    "            img_stack = tf.stack(img_stack, axis=-1)                 # (bs, N, h, wï¼Œcolor, K*K) \n",
    "        else:\n",
    "            # k_diff = (kernel[index - 1]**2 - kernel[index]**2) // 2\n",
    "            k_diff = (kernel[index-1] - kernel[index]) // 2\n",
    "            k_chosen = []\n",
    "            for i in range(k_diff, kernel[index-1]-k_diff):\n",
    "                k_chosen += [i*kernel[index-1]+j for j in range(k_diff, kernel[index-1]-k_diff)]\n",
    "            # img_stack = img_stack[..., k_diff:-k_diff]\n",
    "            img_stack = tf.convert_to_tensor(img_stack.numpy()[..., k_chosen])\n",
    "        pred_img.append(tf.reduce_sum(tf.math.multiply(core[K], img_stack), axis=-1, keepdims=False))\n",
    "    pred_img = tf.stack(pred_img, axis=0)                           # (nb_kernels, bs, N, h, w, color)\n",
    "    pred_img_i = tf.reduce_mean(pred_img, axis=0, keepdims=False)   # (bs, N, h, w, color)\n",
    "\n",
    "    pred_img_i += bias\n",
    "\n",
    "    pred_img = tf.reduce_mean(pred_img_i, axis=1, keepdims=False)          # (bs, h, w, color)\n",
    "    return pred_img, pred_img_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "n_clusters = 1\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "\n",
    "pred_Y_clustered = []\n",
    "for step, (test_x, test_y) in enumerate(test_dataset.take(num_tested)):\n",
    "    print(test_x.shape)\n",
    "    pred_y, _, core = model(test_x, tf.expand_dims(test_x[...,0], axis=-1))\n",
    "    batch_size, N, height, width, color = tf.expand_dims(test_x[...,0], axis=-1).shape \n",
    "    core, bias = model.kernel_pred._convert_dict(core, batch_size, N, height, width, color)\n",
    "\n",
    "    core3_all = tf.reshape(core[3], [-1, 9]).numpy()\n",
    "    print(core3_all.shape)\n",
    "    \n",
    "    y_preds = kmeans.fit_predict(core3_all)\n",
    "    core3_all_clustered = kmeans.cluster_centers_[kmeans.labels_]  # use kmeans to cluster the kernels\n",
    "    core3_all_clustered = core3_all_clustered.reshape(batch_size, N, height, width, color, -1)\n",
    "    core3_all_clustered = dict({3: core3_all_clustered}) # use dict\n",
    "    print(core3_all_clustered[3].shape)\n",
    "    \n",
    "    pred_test_y3, _ = apply_filtering(test_x, core, bias, kernel_size = [3])\n",
    "    pred_test_y3_clustered, _ = apply_filtering(test_x, core3_all_clustered, bias, kernel_size = [3])\n",
    "    \n",
    "    pred_Y_clustered.append(pred_test_y3_clustered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (50,10*num_tested))\n",
    "i = 1\n",
    "    \n",
    "for n in range(num_tested):\n",
    "    plt.subplot(num_tested,3,i)\n",
    "    plt.imshow(test_X[n].numpy().squeeze(), cmap='gray')\n",
    "    #plt.title('noise var {:.3f}'.format(test_x[n][...,1].mean()))\n",
    "    plt.axis('off')\n",
    "    i += 1\n",
    "\n",
    "    plt.subplot(num_tested,3,i)\n",
    "    plt.imshow(test_Y[n].numpy().squeeze(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    i += 1\n",
    "    \n",
    "    plt.subplot(num_tested,3,i)\n",
    "    plt.imshow(pred_Y_clustered[n].numpy().squeeze(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    i += 1\n",
    "\n",
    "plt.savefig('./results/images/transfer_to_div2k/full_images/outputs_ks3_by_clustered_kernels_n1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "def error(x1, x2, mode='mse'):\n",
    "    if mode == 'mse':\n",
    "        return np.mean(np.square(x1-x2))\n",
    "    elif mode == 'mae':\n",
    "        return np.mean(np.abs(x1-x2))\n",
    "    return\n",
    "\n",
    "psnr_gt_n = ssim_gt_n = error_gt_n = 0\n",
    "psnr_r_n = ssim_r_n = error_r_n = 0\n",
    "for i in range(num_tested):\n",
    "    psnr_gt_n += psnr(test_X[i].numpy().squeeze(), test_Y[i].numpy().squeeze(), data_range=1)\n",
    "    ssim_gt_n += ssim(test_X[i].numpy().squeeze(), test_Y[i].numpy().squeeze(), data_range=1)\n",
    "    error_gt_n += error(test_X[i].numpy().squeeze(), test_Y[i].numpy().squeeze())\n",
    "    \n",
    "    psnr_r_n += psnr(pred_Y_clustered[i].numpy().squeeze(), test_Y[i].numpy().squeeze(), data_range=1)\n",
    "    ssim_r_n += ssim(pred_Y_clustered[i].numpy().squeeze(), test_Y[i].numpy().squeeze(), data_range=1)\n",
    "    error_r_n += error(pred_Y_clustered[i].numpy().squeeze(), test_Y[i].numpy().squeeze())\n",
    "\n",
    "print('Evaluation of ground truth and noised images:')\n",
    "print('psnr:{:.3f}\\tssmi:{:.3f}\\tmse:{:.3f}'.format(psnr_gt_n/num_tested, ssim_gt_n/num_tested, error_gt_n/num_tested))\n",
    "\n",
    "print('\\nEvaluation of recovered images and noised images:')\n",
    "print('psnr:{:.3f}\\tssmi:{:.3f}\\tmse:{:.3f}'.format(psnr_r_n/num_tested, ssim_r_n/num_tested, error_r_n/num_tested))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the patches information to decide which kernels to apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 5\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "\n",
    "core3_all = []\n",
    "for step, (batch_test_X, batch_test_Y) in enumerate(test_dataset.take(1)):\n",
    "    pred_test_Y, _, core = model(batch_test_X, tf.expand_dims(batch_test_X[...,0], axis=-1))\n",
    "    \n",
    "    batch_size, N, height, width, color = tf.expand_dims(batch_test_X[...,0], axis=-1).shape \n",
    "    core, bias = model.kernel_pred._convert_dict(core, batch_size, N, height, width, color)\n",
    "    \n",
    "    core3 = tf.reshape(core[3], [-1,9]).numpy()\n",
    "    core3_all.append(core3)\n",
    "\n",
    "core3_all = np.concatenate(core3_all, axis=0)\n",
    "kmeans.fit(core3_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_test_X_flatten = []\n",
    "K = 3\n",
    "frame_pad = tf.pad(batch_test_X, paddings=[[0,0], [0,0], [K//2,K//2], [K//2,K//2], [0,0]], mode='constant')\n",
    "for i in range(K):\n",
    "    for j in range(K):\n",
    "        batch_test_X_flatten.append(frame_pad[:, :, i:i+height, j:j+width,:])\n",
    "batch_test_X_flatten = tf.stack(batch_test_X_flatten, axis=-1)       \n",
    "print(batch_test_X_flatten.shape)\n",
    "\n",
    "batch_test_X_flatten = batch_test_X_flatten.numpy().reshape(-1, 9)\n",
    "print(batch_test_X_flatten.shape)\n",
    "\n",
    "test_all = dict()\n",
    "for i in range(n_clusters):\n",
    "    test_all[i] = batch_test_X_flatten[np.where(kmeans.labels_==i)[0]].mean(axis=0).reshape(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "def simulate_patch(patch, test_all):\n",
    "    best_ssim = 0\n",
    "    for k,v in test_all.items():\n",
    "        cur_ssim = ssim(patch, v.flatten())\n",
    "        if cur_ssim > best_ssim:\n",
    "            best_ssim = cur_ssim\n",
    "            simulated_patch = patch\n",
    "            label = k\n",
    "    return label, simulated_patch\n",
    "\n",
    "simulated_patches = []\n",
    "labels = []\n",
    "for patch in batch_test_X_flatten:\n",
    "    label, simulated_patch = simulate_patch(patch, test_all)\n",
    "    simulated_patches.append(simulated_patch)\n",
    "    labels.append(label)\n",
    "simulated_patches = np.array(simulated_patches)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(labels.shape)\n",
    "print(simulated_patches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core3_all_simulated = kmeans.cluster_centers_[labels]\n",
    "core3_all_simulated = core3_all_simulated.reshape(batch_size, N, height, width, color, -1)\n",
    "core3_all_simulated = dict({3: core3_all_simulated}) # use dict\n",
    "\n",
    "pred_test_Y3_simulated, _ = apply_filtering(batch_test_X, core3_all_simulated, bias, kernel_size = [3])\n",
    "pred_test_Y3_simulated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (50,10))\n",
    "i = 1\n",
    "    \n",
    "for n in range(1):\n",
    "    plt.subplot(1,3,i)\n",
    "    plt.imshow(test_X[n].numpy().squeeze(), cmap='gray')\n",
    "    #plt.title('noise var {:.3f}'.format(test_x[n][...,1].mean()))\n",
    "    plt.axis('off')\n",
    "    i += 1\n",
    "\n",
    "    plt.subplot(1,3,i)\n",
    "    plt.imshow(test_Y[n].numpy().squeeze(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    i += 1\n",
    "    \n",
    "    plt.subplot(1,3,i)\n",
    "    plt.imshow(pred_test_Y3_simulated[n].numpy().squeeze(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    i += 1\n",
    "\n",
    "plt.savefig('./results/images/transfer_to_div2k/full_images/outputs_ks3_by_simulated_kernels.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2gpu",
   "language": "python",
   "name": "tf2gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
