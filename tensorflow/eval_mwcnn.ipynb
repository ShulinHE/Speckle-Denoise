{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T14:54:01.757258Z",
     "start_time": "2020-06-03T14:53:56.223999Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from data import read_data\n",
    "from utils import add_noise_est, normalize, add_noise, squeeze_patches\n",
    "\n",
    "#from model_global_dfn import GDFN\n",
    "from model_baseline import Unet\n",
    "from model_mwcnn import MWCNN\n",
    "from model_mwkpn import MWKPN\n",
    "from model_kpn import KPN, LossFunc, LossBasic\n",
    "\n",
    "gpu_ok = tf.test.is_gpu_available()\n",
    "print(\"tf version:\", tf.__version__)\n",
    "print(\"use GPU:\", gpu_ok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse de l'influence de l'ondelette - Unet - Speckle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''préparation des données'''\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "(train_X_p, train_Y_p), (test_X_p, test_Y_p) = read_data('speckle')\n",
    "N_ims= len(train_X_p)\n",
    "\n",
    "train_X_p, label_train_X_p = squeeze_patches(train_X_p)\n",
    "train_Y_p, label_train_Y_p = squeeze_patches(train_Y_p)\n",
    "test_X_p, label_test_X_p = squeeze_patches(test_X_p)\n",
    "test_Y_p, label_test_Y_p = squeeze_patches(test_Y_p)\n",
    "\n",
    "train_X_p = train_X_p[:,np.newaxis,...]\n",
    "train_Y_p = train_Y_p[...,np.newaxis]\n",
    "test_X_p = test_X_p[:,np.newaxis,...]\n",
    "test_Y_p = test_Y_p[...,np.newaxis]\n",
    "\n",
    "print('\\nTrain data:')\n",
    "print('train_X_p:',train_X_p.shape)\n",
    "print('train_Y_p:',train_Y_p.shape)\n",
    "\n",
    "print('\\nTest data:')\n",
    "print('test_X_p:',test_X_p.shape)\n",
    "print('test_Y_p:',test_Y_p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_noise_map = False   # if True, concatenate a noise map to the input\n",
    "#use_noise_est = False   # if True, use a model to estimate noise map, if False, use known info\n",
    "\n",
    "if not use_noise_map:\n",
    "    train_X_p = train_X_p[...,0][..., np.newaxis]\n",
    "    test_X_p = test_X_p[...,0][..., np.newaxis]\n",
    "\n",
    "train_X_p = train_X_p.squeeze(1)\n",
    "test_X_p = test_X_p.squeeze(1)\n",
    "    \n",
    "print('Train data:')\n",
    "print('train_X_p:',train_X_p.shape)\n",
    "print('train_Y_p:',train_Y_p.shape)\n",
    "\n",
    "print('\\nTest data:')\n",
    "print('test_X_p:',test_X_p.shape)\n",
    "print('test_Y_p:',test_Y_p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tf.data API to shuffle and batch data.\n",
    "batch_size = 16\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_X_p,train_Y_p))\n",
    "train_dataset = train_dataset.repeat().shuffle(5000).batch(batch_size).prefetch(1)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_X_p,test_Y_p))\n",
    "test_dataset = test_dataset.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Unet(color=False, kernel_size=5, channel_att=False, spatial_att=True, if_wavelet=True)\n",
    "model = MWCNN(color = False, kernel_size=3, channel_att=False, spatial_att=False)\n",
    "\n",
    "#filename = 'unet_satt_bias_combinedloss'\n",
    "filename = 'mwcnn_satt_combinedloss_nvar'\n",
    "\n",
    "load_model = True\n",
    "if load_model:\n",
    "    model.load_weights(filepath = \"model_weights/transfer_to_speckle/\" + filename + \".ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step, (batch_test_X, batch_test_Y) in enumerate(test_dataset.take(1)):\n",
    "    pred_test_Y, pred_test_Y_wavelet = model(batch_test_X)\n",
    "    \n",
    "    pred_test_Y = pred_test_Y.numpy()\n",
    "    pred_test_Y_wavelet = pred_test_Y_wavelet.numpy()\n",
    "    batch_test_Y = batch_test_Y.numpy()\n",
    "    batch_test_X = batch_test_X.numpy()\n",
    "    \n",
    "    print(pred_test_Y.shape)\n",
    "    print(pred_test_Y_wavelet.shape)\n",
    "    \n",
    "#pred_test_Y_wavelet = np.split(pred_test_Y_wavelet, 4, -1)  # a list of length 4 with every element: (16,64,64,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "\n",
    "plt.figure(figsize = (25,10*batch_size))\n",
    "for i in range(batch_size):\n",
    "    '''GT'''\n",
    "    original = batch_test_Y[i].squeeze()\n",
    "    LL, (LH, HL, HH) = pywt.dwt2(original, 'haar')\n",
    "    \n",
    "    plt.subplot(batch_size*2, 5, 10*i+1)\n",
    "    plt.imshow(original, cmap='gray')\n",
    "    plt.title('original image')\n",
    "\n",
    "    plt.subplot(batch_size*2, 5, 10*i+2)\n",
    "    plt.imshow(LL, cmap='gray')\n",
    "    plt.title('approximation')\n",
    "    \n",
    "    plt.subplot(batch_size*2, 5, 10*i+3)\n",
    "    plt.imshow(LH, cmap='gray')\n",
    "    plt.title('horizeontal detail')\n",
    "    \n",
    "    plt.subplot(batch_size*2, 5, 10*i+4)\n",
    "    plt.imshow(HL, cmap='gray')\n",
    "    plt.title('vertical detail')\n",
    "    \n",
    "    plt.subplot(batch_size*2, 5, 10*i+5)\n",
    "    plt.imshow(HH, cmap='gray')\n",
    "    plt.title('diagonal detail')\n",
    "    #plt.axis('off')\n",
    "    \n",
    "    '''predictions'''\n",
    "    plt.subplot(batch_size*2, 5, 10*i+6)\n",
    "    plt.imshow(pred_test_Y[i].squeeze(), cmap='gray')\n",
    "    plt.title('recovered image')\n",
    "\n",
    "    plt.subplot(batch_size*2, 5, 10*i+7)\n",
    "    plt.imshow(pred_test_Y_wavelet[i][:,:,0].squeeze(), cmap='gray')\n",
    "    plt.title('1st detail')\n",
    "    \n",
    "    plt.subplot(batch_size*2, 5, 10*i+8)\n",
    "    plt.imshow(pred_test_Y_wavelet[i][:,:,4].squeeze(), cmap='gray')\n",
    "    plt.title('5th detail')\n",
    "    \n",
    "    plt.subplot(batch_size*2, 5, 10*i+9)\n",
    "    plt.imshow(pred_test_Y_wavelet[i][:,:,8].squeeze(), cmap='gray')\n",
    "    plt.title('9th detail')\n",
    "    \n",
    "    plt.subplot(batch_size*2, 5, 10*i+10)\n",
    "    plt.imshow(pred_test_Y_wavelet[i][:,:,12].squeeze(), cmap='gray')\n",
    "    plt.title('13th detail')\n",
    "    #plt.axis('off')\n",
    "    \n",
    "plt.savefig('./eval/mwcnn.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2gpu",
   "language": "python",
   "name": "tf2gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
