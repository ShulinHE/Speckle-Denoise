{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-05-20T07:05:53.590Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from data import read_data\n",
    "from model_global_dfn import GDFN\n",
    "from model_local_dfn import DFN, CombinedLoss\n",
    "from model_simple_local_dfn import DnCNN\n",
    "\n",
    "gpu_ok = tf.test.is_gpu_available()\n",
    "print(\"tf version:\", tf.__version__)\n",
    "print(\"use GPU:\", gpu_ok)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T14:11:31.947499Z",
     "start_time": "2020-05-12T14:11:31.663258Z"
    }
   },
   "source": [
    "# 避免显卡显存小而报错，显存自适应分配\n",
    "physical_devices=tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0],True)\n",
    "\n",
    "# 给显存分配几个子虚拟内存\n",
    "tf.config.experimental.set_virtual_device_configuration(\n",
    "    physical_devices[0],\n",
    "    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2048)])\n",
    "\n",
    "# 发现容易报错This is probably because cuDNN failed to initialize，是显存还是不够的原因"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices=tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T03:26:36.876191Z",
     "start_time": "2020-05-20T03:26:36.700666Z"
    }
   },
   "outputs": [],
   "source": [
    "ims = read_data('imagenet')\n",
    "\n",
    "N_ims, h, w, _ = ims.shape\n",
    "ims = ims[:N_ims].astype(np.float32)\n",
    "ims_noise = ims_noise[:N_ims].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T03:26:37.718936Z",
     "start_time": "2020-05-20T03:26:37.710963Z"
    }
   },
   "outputs": [],
   "source": [
    "# training hyperparameters\n",
    "batch_size = 16\n",
    "lr = 5e-4\n",
    "epochs = 80\n",
    "test_size = 0.1\n",
    "training_steps = int(epochs*N_ims*(1-test_size)/batch_size)\n",
    "display_step = int(training_steps/epochs*0.5)\n",
    "\n",
    "print(training_steps)\n",
    "print(display_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T03:26:52.319882Z",
     "start_time": "2020-05-20T03:26:51.919941Z"
    }
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "train_X, train_Y = ims_noise, ims\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(train_X, train_Y, test_size=test_size, random_state=42)\n",
    "\n",
    "print('Training X: ', train_X.shape, train_X.dtype)\n",
    "print('Training Y: ', train_Y.shape, train_Y.dtype)\n",
    "print('Testing X: ', test_X.shape, test_X.dtype)\n",
    "print('Testing Y: ', test_Y.shape, test_Y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T03:26:52.938217Z",
     "start_time": "2020-05-20T03:26:52.912286Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use tf.data API to shuffle and batch data.\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_X,train_Y))\n",
    "train_dataset = train_dataset.repeat().shuffle(5000).batch(batch_size).prefetch(1)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_X,test_Y))\n",
    "test_dataset = test_dataset.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T03:26:54.748374Z",
     "start_time": "2020-05-20T03:26:54.688533Z"
    }
   },
   "outputs": [],
   "source": [
    "'''please choose the model from 'dfn' and 'gdfn' '''\n",
    "choice = 'gdfn'\n",
    "\n",
    "if choice == 'dfn':\n",
    "    model = DFN(color = False, filter_size=(3,3), channel_att=False, spatial_att=False)\n",
    "elif choice == 'gdfn':\n",
    "    model = GDFN(color = False, num_filters = 9, channel_att=False, spatial_att=False)\n",
    "else:\n",
    "    assert\n",
    "\n",
    "load_model = False\n",
    "if load_model:\n",
    "    model.load_weights(filepath=\"model_weights/local_dfn.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T03:26:56.126686Z",
     "start_time": "2020-05-20T03:26:56.121699Z"
    }
   },
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer = tf.optimizers.Adam(lr)\n",
    "#optimizer = tf.optimizers.SGD(learning_rate=lr, momentum=0.9, nesterov=True, decay=1e-6)\n",
    "\n",
    "# loss func\n",
    "loss_func = tf.keras.losses.MeanAbsoluteError()\n",
    "# loss_func = CombinedLoss(gradient_L1 = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T03:27:03.479014Z",
     "start_time": "2020-05-20T03:27:03.468046Z"
    }
   },
   "outputs": [],
   "source": [
    "# optimization process\n",
    "def lr_fn(step, cur_lr=1e-4):\n",
    "    '''exponetial'''\n",
    "    next_epoch = step * batch_size // int(N_ims*(1-test_size)) - (step-1) * batch_size // int(N_ims*(1-test_size))\n",
    "    return cur_lr * (0.95**next_epoch)\n",
    "\n",
    "def run_optimization(step, train_X, train_Y):\n",
    "    with tf.GradientTape() as g:\n",
    "        pred_Y, _ = model(train_X) \n",
    "        loss = loss_func(pred_Y, train_Y)\n",
    "    \n",
    "    gradients = g.gradient(loss, model.trainable_variables)\n",
    "    optimizer.learning_rate = lr_fn(step, optimizer.learning_rate.numpy())\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T03:27:03.854046Z",
     "start_time": "2020-05-20T03:27:03.844041Z"
    }
   },
   "outputs": [],
   "source": [
    "# 发现用tensorboard summary会让速度变得很慢很慢\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "test_steps = []\n",
    "lrs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-05-20T06:01:12.000Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_train_loss = total_train = 0\n",
    "for step, (batch_X, batch_Y) in enumerate(train_dataset.take(training_steps), start = 1):\n",
    "    train_loss = run_optimization(step, batch_X, batch_Y)\n",
    "    mean_train_loss +=  train_loss.numpy()\n",
    "    total_train += 1\n",
    "    train_losses.append(train_loss.numpy())\n",
    "    lrs.append(optimizer.lr.numpy())\n",
    "    \n",
    "    if step % display_step == 0:\n",
    "        mean_test_loss = total_test = 0\n",
    "        for (batch_test_X, batch_test_Y) in test_dataset:\n",
    "            pred_test_Y, _ = model(batch_test_X)\n",
    "            test_loss = loss_func(pred_test_Y, batch_test_Y)\n",
    "            \n",
    "            mean_test_loss += test_loss.numpy()\n",
    "            total_test += 1\n",
    "        \n",
    "        mean_test_loss /= total_test\n",
    "        mean_train_loss /= total_train\n",
    "        test_losses.append(mean_test_loss)\n",
    "        test_steps.append(step)\n",
    "\n",
    "        print(\"step: {:3d}/{:3d} || train loss: {:.5f} || test loss: {:.5f}\"\n",
    "              .format(step, training_steps, mean_train_loss, mean_test_loss))\n",
    "        \n",
    "        mean_train_loss = total_train = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = './logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-05-20T06:01:15.806Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(131)\n",
    "plt.plot(range(50,training_steps), train_losses[50:])\n",
    "plt.xlabel('steps')\n",
    "plt.ylabel('value')\n",
    "plt.title('training loss')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.plot(test_steps, test_losses)\n",
    "plt.xlabel('steps')\n",
    "plt.ylabel('value')\n",
    "plt.title('test loss')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.plot(range(training_steps), lrs)\n",
    "plt.xlabel('steps')\n",
    "plt.ylabel('value')\n",
    "plt.title('learning rate')\n",
    "\n",
    "plt.savefig(log_dir+'global_dfn_'+current_time+'.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T12:13:55.256357Z",
     "start_time": "2020-05-19T12:13:42.744824Z"
    }
   },
   "outputs": [],
   "source": [
    "total_test_loss = []\n",
    "for (batch_test_X, batch_test_Y) in test_dataset:\n",
    "    pred_test_Y, _ = model(batch_test_X)\n",
    "    test_loss = loss_func(pred_test_Y, batch_test_Y)\n",
    "    total_test_loss.append(test_loss.numpy())\n",
    "total_test_loss = np.mean(total_test_loss)\n",
    "\n",
    "print(\"Test data loss: {:.3f}\".format(total_test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T18:19:06.579077Z",
     "start_time": "2020-05-19T18:19:06.147232Z"
    }
   },
   "outputs": [],
   "source": [
    "# draw test figures\n",
    "test_x = test_X[:batch_size] \n",
    "test_y = test_Y[:batch_size] \n",
    "pred_y, _ = model(test_x)\n",
    "    \n",
    "plt.figure(figsize = (15,5*batch_size))\n",
    "i = 1\n",
    "    \n",
    "for n in range(batch_size):\n",
    "    plt.subplot(batch_size,3,i)\n",
    "    plt.imshow(test_x[n].squeeze(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    i += 1\n",
    "\n",
    "    plt.subplot(batch_size,3,i)\n",
    "    plt.imshow(test_y[n].squeeze(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    i += 1\n",
    "    \n",
    "    plt.subplot(batch_size,3,i)\n",
    "    plt.imshow(pred_y[n].numpy().squeeze(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    i += 1\n",
    "\n",
    "plt.savefig('./results/images/global_dfn_'+current_time+'.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T16:43:21.832233Z",
     "start_time": "2020-05-19T16:43:21.818270Z"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "def error(x1, x2, mode='mse'):\n",
    "    if mode == 'mse':\n",
    "        return np.mean(np.square(x1-x2))\n",
    "    elif mode == 'mae':\n",
    "        return np.mean(np.abs(x1-x2))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = []\n",
    "test_Y = []\n",
    "pred_Y = []\n",
    "for inputs, target in test_dataset:\n",
    "    test_X.append(inputs.numpy())\n",
    "    test_Y.append(target.numpy())\n",
    "    \n",
    "    outputs,_ = model(inputs)\n",
    "    pred_Y.append(outputs.numpy())\n",
    "\n",
    "test_X = np.concatenate(test_X, axis=0)\n",
    "test_Y = np.concatenate(test_Y, axis=0)\n",
    "pred_Y = np.concatenate(pred_Y, axis=0)\n",
    "\n",
    "pred_data_range = pred_Y.max() - pred_Y.min()\n",
    "print('Evaluation of ground truth and noised images:')\n",
    "print('psnr:{:.3f}\\tssmi:{:.3f}\\tmse:{:.3f}'.format(psnr(test_X.squeeze(), test_Y.squeeze(), data_range=1), \n",
    "                                        ssim(test_X.squeeze(), test_Y.squeeze(), data_range=1),\n",
    "                                        error(test_X, test_Y)))\n",
    "\n",
    "print('\\nEvaluation of recovered images and noised images:')\n",
    "print('psnr:{:.3f}\\tssmi:{:.3f}\\tmse:{:.3f}'.format(psnr(pred_Y, test_Y, data_range=pred_data_range), \n",
    "                                        ssim(pred_Y.squeeze(), test_Y.squeeze(), data_range=pred_data_range),\n",
    "                                        error(pred_Y, test_Y)))\n",
    "\n",
    "print('\\nGround Truth:')\n",
    "print('max:{:.3f}\\tmin:{:.3f}\\tmean:{:.3f}'.format(test_Y.max(), test_Y.min(), test_Y.mean()))\n",
    "\n",
    "print('\\nNoised images:')\n",
    "print('max:{:.3f}\\tmin:{:.3f}\\tmean:{:.3f}'.format(test_X.max(), test_X.min(), test_X.mean()))\n",
    "\n",
    "print('\\nRecoverd images:')\n",
    "print('max:{:.3f}\\tmin:{:.3f}\\tmean:{:.3f}'.format(pred_Y.max(), pred_Y.min(), pred_Y.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T14:54:41.411260Z",
     "start_time": "2020-05-11T14:54:41.408269Z"
    }
   },
   "outputs": [],
   "source": [
    "# draw loss\n",
    "# 1.在命令行输入：\n",
    "# python -m tensorboard.main --logdir logs\n",
    "# 2.在浏览器输入\n",
    "# http://localhost:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T12:16:40.948366Z",
     "start_time": "2020-05-19T12:16:40.863590Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save TF model.\n",
    "model.save_weights(filepath=\"model_weights/global_dfn.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2gpu",
   "language": "python",
   "name": "tf2gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
