{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T14:54:01.757258Z",
     "start_time": "2020-06-03T14:53:56.223999Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from data import read_data\n",
    "from utils import add_noise_est, normalize, add_noise, squeeze_patches\n",
    "\n",
    "#from model_global_dfn import GDFN\n",
    "from model_baseline import Unet\n",
    "from model_mwcnn import MWCNN\n",
    "from model_mwkpn import MWKPN\n",
    "from model_kpn import KPN, LossFunc, LossBasic\n",
    "\n",
    "gpu_ok = tf.test.is_gpu_available()\n",
    "print(\"tf version:\", tf.__version__)\n",
    "print(\"use GPU:\", gpu_ok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transfer learning - from speckle noise to gaussian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ims = read_data('imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ims, h, w, _ = ims.shape\n",
    "ims = ims[:N_ims].astype(np.float32)\n",
    "\n",
    "noise_est = False        # if True, use model to estimate the noise; if Fasle, use known noise info\n",
    "\n",
    "variances = np.arange(1,11) * 5e-4\n",
    "#variances = [15*5e-4]\n",
    "\n",
    "# for noise estimation map, there should be different noise levels\n",
    "ims_noise = []\n",
    "ims_noise_with_est = []\n",
    "ims_split = np.array_split(ims, len(variances))\n",
    "for i, var in enumerate(variances):\n",
    "    ims_noise.append(normalize(add_noise(ims_split[i], mean=0, var=var, n_type='gaussian')))\n",
    "    if not noise_est:\n",
    "        ims_noise_with_est.append(add_noise_est(ims_noise[i], if_est=False, var = var))\n",
    "    else:\n",
    "        ims_noise_with_est.append(add_noise_est(ims_noise[i], if_est=True))\n",
    "ims_noise = np.concatenate(ims_noise)\n",
    "ims_noise_with_est = np.concatenate(ims_noise_with_est)\n",
    "\n",
    "print(ims.shape)\n",
    "print(ims_noise.shape)\n",
    "print(ims_noise_with_est.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "test_size = 0.1\n",
    "\n",
    "train_X, train_Y = ims_noise, ims\n",
    "#train_X, train_Y = ims_noise_with_est, ims\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(train_X, train_Y, test_size=test_size, random_state=42)\n",
    "\n",
    "train_X = train_X[:,np.newaxis,...]\n",
    "test_X = test_X[:,np.newaxis,...]\n",
    "\n",
    "print('Training X: ', train_X.shape, train_X.dtype)\n",
    "print('Training Y: ', train_Y.shape, train_Y.dtype)\n",
    "print('Testing X: ', test_X.shape, test_X.dtype)\n",
    "print('Testing Y: ', test_Y.shape, test_Y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tf.data API to shuffle and batch data.\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_X,train_Y))\n",
    "train_dataset = train_dataset.repeat().shuffle(5000).batch(batch_size).prefetch(1)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_X,test_Y))\n",
    "test_dataset = test_dataset.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KPN(color=False, burst_length=1, blind_est=True, sep_conv=False, kernel_size=[3,5,7],\n",
    "            channel_att=False, spatial_att=True, core_bias=True, use_bias=True)\n",
    "#model = MWKPN(color=False, burst_length=1, blind_est=True, sep_conv=False, kernel_size=[3,5,7],\n",
    "#             channel_att=False, spatial_att=True, core_bias=True, use_bias=True)\n",
    "\n",
    "filename = 'kpn_ks357_satt_bias_combinedloss_nvar'\n",
    "\n",
    "load_model = True\n",
    "if load_model:\n",
    "    model.load_weights(filepath = \"model_weights/transfer_to_speckle/\" + filename + \".ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = LossBasic(gradient_L1 = True)\n",
    "\n",
    "total_test_loss = []\n",
    "for (batch_test_X, batch_test_Y) in test_dataset:\n",
    "    #pred_test_Y, _ = model(batch_test_X, batch_test_X)\n",
    "    pred_test_Y, _, _ = model(batch_test_X, tf.expand_dims(batch_test_X[...,0], axis=-1))\n",
    "    test_loss = loss_func(pred_test_Y, batch_test_Y)\n",
    "    total_test_loss.append(test_loss.numpy())\n",
    "total_test_loss = np.mean(total_test_loss)\n",
    "\n",
    "print(\"Test data loss: {:.3f}\".format(total_test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw test figures\n",
    "test_x = test_X[:batch_size] \n",
    "test_y = test_Y[:batch_size] \n",
    "#pred_y, _ = model(test_x, test_x)\n",
    "pred_y, _, _  = model(test_x, tf.expand_dims(test_x[...,0], axis=-1))\n",
    "    \n",
    "plt.figure(figsize = (15,5*batch_size))\n",
    "i = 1\n",
    "    \n",
    "for n in range(batch_size):\n",
    "    plt.subplot(batch_size,3,i)\n",
    "    plt.imshow(test_x[n][...,0].squeeze(), cmap='gray')\n",
    "    #plt.title('noise var {:.3f}'.format(test_x[n][...,1].mean()))\n",
    "    plt.axis('off')\n",
    "    i += 1\n",
    "\n",
    "    plt.subplot(batch_size,3,i)\n",
    "    plt.imshow(test_y[n].squeeze(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    i += 1\n",
    "    \n",
    "    plt.subplot(batch_size,3,i)\n",
    "    plt.imshow(pred_y[n].numpy().squeeze(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    i += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2gpu",
   "language": "python",
   "name": "tf2gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
