{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T00:02:46.534921Z",
     "start_time": "2020-05-29T00:02:38.614038Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import notebook, tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import torchvision.models as models\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from model_kpn import KPN, LossBasic\n",
    "#from model_baseline import Unet\n",
    "#from model_gdfn import GDFN\n",
    "\n",
    "from data import ims, ims_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T00:02:47.743715Z",
     "start_time": "2020-05-29T00:02:46.535917Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T00:02:47.926203Z",
     "start_time": "2020-05-29T00:02:47.749678Z"
    }
   },
   "outputs": [],
   "source": [
    "N_ims, h, w, color = ims.shape\n",
    "ims = ims[:N_ims].astype(np.float32).transpose(0,3,1,2)\n",
    "ims_noise = ims_noise[:N_ims].astype(np.float32).transpose(0,3,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T00:02:47.931187Z",
     "start_time": "2020-05-29T00:02:47.927196Z"
    }
   },
   "outputs": [],
   "source": [
    "# training hyperparameters\n",
    "batch_size = 8\n",
    "lr = 3e-4\n",
    "epochs = 50\n",
    "test_size = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T00:02:48.152594Z",
     "start_time": "2020-05-29T00:02:47.932182Z"
    }
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "train_X, train_Y = ims_noise, ims\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(train_X, train_Y, test_size=test_size, random_state=42)\n",
    "\n",
    "train_X = train_X[:,np.newaxis,...]\n",
    "test_X = test_X[:,np.newaxis,...]\n",
    "\n",
    "print('Training X: ', train_X.shape, train_X.dtype, train_X.max(), train_X.min())\n",
    "print('Training Y: ', train_Y.shape, train_Y.dtype, train_Y.max(), train_Y.min())\n",
    "print('Testing X: ', test_X.shape, test_X.dtype, test_X.max(), test_X.min())\n",
    "print('Testing Y: ', test_Y.shape, test_Y.dtype, test_Y.max(), test_Y.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T00:02:50.489451Z",
     "start_time": "2020-05-29T00:02:50.481473Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):      #这个方法是必须要有的，用于按照索引读取每个元素的具体内容\n",
    "        return self.X[index], self.Y[index]\n",
    "    \n",
    "    def __len__(self):                 #这个函数也必须要写，它返回的是数据集的长度，也就是多少张图片，要和loader的长度作区分\n",
    "        return len(self.X)\n",
    "        \n",
    "train_set = MyDataset(train_X, train_Y)\n",
    "test_set = MyDataset(test_X, test_Y)\n",
    "\n",
    "def collate(batch): \n",
    "    inputs = torch.FloatTensor([item[0] for item in batch])\n",
    "    target = torch.FloatTensor([item[1] for item in batch])\n",
    "    return inputs, target\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, collate_fn=collate)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''please choose the model from 'kpn', 'unet' and 'gdfn' '''\n",
    "choice = 'gdfn'\n",
    "\n",
    "if choice == 'kpn':\n",
    "    model = KPN(color=False, burst_length=1, blind_est=True, kernel_size=[3], sep_conv=False, \n",
    "                     channel_att=False, spatial_att=True, core_bias=False).to(device)\n",
    "    mode = 1\n",
    "elif choice == 'unet':\n",
    "    model = Unet(color=False, blind_est=True, channel_att=False, spatial_att=False, core_bias=False).to(device)\n",
    "    mode = 2\n",
    "elif choice == 'gdfn':\n",
    "    model = GDFN(filter_size = (3,3), color=False, blind_est=True, channel_att=False, spatial_att=False, core_bias=False).to(device)\n",
    "    mode = 2\n",
    "else:\n",
    "    assert\n",
    "    \n",
    "print('# model parameters:', sum(param.numel() for param in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T00:09:05.604916Z",
     "start_time": "2020-05-29T00:09:05.414425Z"
    }
   },
   "outputs": [],
   "source": [
    "if_load = False\n",
    "if if_load:\n",
    "    model.load_state_dict(torch.load(r'./model_weights/kpn_satt.pkl'))\n",
    "    #model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T18:41:02.272666Z",
     "start_time": "2020-05-28T18:41:02.267678Z"
    }
   },
   "outputs": [],
   "source": [
    "'''optimizer and loss function'''\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "#scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)  # step_size == epoch\n",
    "                                \n",
    "#loss_func = LossBasic(gradient_L1 = True)\n",
    "loss_func = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T18:41:02.723459Z",
     "start_time": "2020-05-28T18:41:02.719471Z"
    }
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_steps = 0\n",
    "\n",
    "test_losses = []\n",
    "lrs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T19:32:51.138191Z",
     "start_time": "2020-05-28T18:41:03.540654Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    # train loss\n",
    "    model.train()\n",
    "    total_train_loss = total =0\n",
    "    progress_bar = notebook.tqdm(train_loader, desc='Training', leave=False) # desc应该是开头的文字提示\n",
    "    for inputs, target in progress_bar:\n",
    "        total += 1\n",
    "        inputs, target = inputs.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        if mode == 1:\n",
    "            outputs,_ = model(inputs, inputs)\n",
    "        elif mode == 2:\n",
    "            outputs = model(inputs)\n",
    "        else:\n",
    "            assert\n",
    "        \n",
    "        loss = loss_func(outputs, target)\n",
    "\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_train_loss += loss.item()\n",
    "        train_losses.append(loss.item())\n",
    "        train_steps += 1\n",
    "        progress_bar.set_description(f'Loss: {loss.item():.5f}')\n",
    "    \n",
    "    total_train_loss /= total\n",
    "    \n",
    "    # test\n",
    "    model.eval()\n",
    "    total_test_loss = total = 0\n",
    "    for inputs, target in test_loader:\n",
    "        total += 1\n",
    "        inputs, target = inputs.to(device), target.to(device)\n",
    "\n",
    "        if mode == 1:\n",
    "            outputs,_ = model(inputs, inputs)\n",
    "        elif mode == 2:\n",
    "            outputs = model(inputs)\n",
    "        else:\n",
    "            assert\n",
    "        \n",
    "        test_loss = loss_func(outputs, target).item()\n",
    "        total_test_loss += test_loss\n",
    "    total_test_loss /= total\n",
    "    test_losses.append(total_test_loss)\n",
    "    \n",
    "    tqdm.write(f'Epoch #{epoch + 1:3d}\\tTrain Loss: {total_train_loss:.5f}\\tTest Loss: {total_test_loss:.5f}')\n",
    "    \n",
    "    lrs.append(optimizer.param_groups[0]['lr'])\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T19:34:28.416031Z",
     "start_time": "2020-05-28T19:34:27.964239Z"
    }
   },
   "outputs": [],
   "source": [
    "# 发现用tensorboard summary会让速度变得很慢很慢\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = './logs/'\n",
    "\n",
    "# draw train info\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(131)\n",
    "plt.plot(range(train_steps), np.log(train_losses))\n",
    "plt.xlabel('steps')\n",
    "plt.ylabel('value in logarithm')\n",
    "plt.title('training loss')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.plot(range(epochs), np.log(test_losses))\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('value in logarithm')\n",
    "plt.title('test loss')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.plot(range(epochs), lrs)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('value')\n",
    "plt.title('learning rate')\n",
    "\n",
    "plt.savefig(log_dir+'kpn_'+current_time+'.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T19:34:39.043358Z",
     "start_time": "2020-05-28T19:34:36.989668Z"
    }
   },
   "outputs": [],
   "source": [
    "# draw test images\n",
    "model.eval()\n",
    "test_X, test_Y = next(iter(test_loader))\n",
    "test_X, test_Y = test_X.to(device), test_Y.to(device)\n",
    "\n",
    "if mode == 1:\n",
    "    pred_Y,_ = model(test_X, test_X)\n",
    "elif mode == 2:\n",
    "    pred_Y = model(test_X)\n",
    "else:\n",
    "    assert\n",
    "\n",
    "plt.figure(figsize = (15,5*batch_size))\n",
    "i = 1\n",
    "for test_x, test_y, pred_y in zip(test_X, test_Y, pred_Y):\n",
    "    plt.subplot(batch_size,3,i)\n",
    "    plt.imshow(test_x.cpu().squeeze(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    i += 1\n",
    "    \n",
    "    plt.subplot(batch_size,3,i)\n",
    "    plt.imshow(test_y.cpu().squeeze(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    i += 1\n",
    "    \n",
    "    plt.subplot(batch_size,3,i)\n",
    "    plt.imshow(pred_y.cpu().detach().numpy().squeeze(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    i += 1\n",
    "plt.savefig('./results/images/kpn_'+current_time+'.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T00:03:31.569838Z",
     "start_time": "2020-05-29T00:03:31.563854Z"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "def error(x1, x2, mode='mse'):\n",
    "    if mode == 'mse':\n",
    "        return np.mean(np.square(x1-x2))\n",
    "    elif mode == 'mae':\n",
    "        return np.mean(np.abs(x1-x2))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T00:07:45.027381Z",
     "start_time": "2020-05-29T00:07:40.067648Z"
    }
   },
   "outputs": [],
   "source": [
    "test_X = []\n",
    "test_Y = []\n",
    "pred_Y = []\n",
    "for inputs, target in test_loader:\n",
    "    test_X.append(inputs.numpy())\n",
    "    test_Y.append(target.numpy())\n",
    "    \n",
    "    inputs, target = inputs.to(device), target.to(device)\n",
    "    \n",
    "    if mode == 1:\n",
    "        outputs,_ = model(inputs, inputs)\n",
    "    elif mode == 2:\n",
    "        outputs = model(inputs)\n",
    "    else:\n",
    "        assert\n",
    "    \n",
    "    pred_Y.append(outputs.cpu().detach().numpy())\n",
    "\n",
    "test_X = np.concatenate(test_X, axis=0)\n",
    "test_Y = np.concatenate(test_Y, axis=0)\n",
    "pred_Y = np.concatenate(pred_Y, axis=0)\n",
    "\n",
    "print('Evaluation of ground truth and noised images:')\n",
    "print('psnr:{:.3f}\\tssmi:{:.3f}\\tmse:{:.3f}'.format(psnr(test_X.squeeze(), test_Y.squeeze(), data_range=1), \n",
    "                                        ssim(test_X.squeeze(), test_Y.squeeze(), data_range=1),\n",
    "                                        error(test_X.squeeze(), test_Y.squeeze())))\n",
    "\n",
    "print('\\nEvaluation of recovered images and noised images:')\n",
    "print('psnr:{:.3f}\\tssmi:{:.3f}\\tmse:{:.3f}'.format(psnr(pred_Y, test_Y, data_range=1), \n",
    "                                        ssim(pred_Y.squeeze(), test_Y.squeeze(), data_range=1),\n",
    "                                        error(pred_Y.squeeze(), test_Y.squeeze())))\n",
    "\n",
    "print('\\nGround Truth:')\n",
    "print('max:{:.3f}\\tmin:{:.3f}\\tmean:{:.3f}'.format(test_Y.max(), test_Y.min(), test_Y.mean()))\n",
    "\n",
    "print('\\nNoised images:')\n",
    "print('max:{:.3f}\\tmin:{:.3f}\\tmean:{:.3f}'.format(test_X.max(), test_X.min(), test_X.mean()))\n",
    "\n",
    "print('\\nRecoverd images:')\n",
    "print('max:{:.3f}\\tmin:{:.3f}\\tmean:{:.3f}'.format(pred_Y.max(), pred_Y.min(), pred_Y.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T19:35:55.836041Z",
     "start_time": "2020-05-28T19:35:55.781188Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "root = r'./model_weights'\n",
    "if not os.path.exists(root):\n",
    "    os.makedirs(root)\n",
    "\n",
    "torch.save(model.state_dict(), root+'/kpn.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2gpu",
   "language": "python",
   "name": "tf2gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
